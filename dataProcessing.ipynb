{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dataProcessing.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Qr1e3YZuRikN","colab_type":"text"},"source":["# Visualizing Income Inequality in the United Stated\n","\n","Author: Sang Truong and Dr. Humberto Barreto, Department of Economics and Management\n","\n","DePauw University, Greencastle, Indiana, 46135, Summer 2019\n","\n","References:\n","\n","*   Color generator: https://www.strangeplanet.fr/work/gradient-generator/index.php\n","\n","*   AmChart documentation:  https://docs.amcharts.com/3/javascriptcharts/AmGraph\n","\n","*   Jackblun's graph: https://jackblun.github.io/Globalinc/html/fig_1980.html"]},{"cell_type":"markdown","metadata":{"id":"qX4F3Ltva5iT","colab_type":"text"},"source":["# Deflator generator"]},{"cell_type":"code","metadata":{"id":"ZvD3CFGya5Fg","colab_type":"code","outputId":"904ad55f-919f-494d-eca7-cf551f6b9b3d","executionInfo":{"status":"ok","timestamp":1566963539431,"user_tz":240,"elapsed":45772,"user":{"displayName":"Sang Truong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCOvDUyD0IVxBIyFjvwy8Ym7mfJeHFjYHDJpFza1w=s64","userId":"12360713090073442907"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import pandas as pd\n","import json\n","from collections import OrderedDict\n","from google.colab import drive\n","from scipy import stats\n","drive.mount('/content/gdrive')\n","in_path = 'gdrive/My Drive/Colab Notebooks/code/'\n","\n","# Import raw data for deflator and CPI\n","raw_deflator = pd.read_csv(in_path + \"raw_deflator.csv\")\n","cpi = pd.read_csv(in_path + 'cpi_deflator.csv')\n","\n","# Eliminate RENTGRW = 0\n","raw_deflator = raw_deflator[raw_deflator.RENTGRS != 0]\n","\n","# Select the household head\n","raw_deflator = raw_deflator[raw_deflator.RELATE == 1]\n","\n","# Generate constants\n","stateList = [1,2,4,5,6,8,9,10,11,12,13,15,16,17,18,19,20,21,22,23,24,25,26,27,\n","             28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,44,45,46,47,48,49,\n","             50,51,53,54,55,56]\n","\n","yearList = [1970, 1980, 1990, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008,\n","        2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017]\n","\n","# Generate deflator grid\n","deflator = pd.DataFrame(columns=stateList)\n","deflator[1] = yearList\n","\n","# Iterate through each year in yearList\n","r = 0\n","for y in yearList:\n","  # Generate year dataframe \n","  year = raw_deflator[raw_deflator.YEAR == y]\n","  \n","  # Iterate through each state\n","  c = 0\n","  for s in stateList:\n","    state = year[year.STATEFIP == s]\n","    # Calculate median of RENTGRS\n","    deflator.iloc[r, c] = state.median().RENTGRS\n","    c = c + 1\n","  r = r + 1\n","\n","# Calculate COLI\n","for c in range (0, 51):\n","  for r in range(0, len(deflator)):\n","    deflator.iloc[r, c] = 0.44*deflator.iloc[r, c] + 0.56\n","\n","# Compute average of COLI\n","deflator['AVERAGE'] = deflator.mean(axis = 1)\n","\n","# Normalize COLI with average COLI\n","for c in range (0, 51):\n","  for r in range(0, len(deflator)):\n","    deflator.iloc[r, c] = deflator.iloc[r, c]/deflator.iloc[r, 51]\n","\n","deflator = deflator.rename(index = {0: 1970, 1: 1980, 2: 1990, 3: 2000, 4: 2001,\n","                         5: 2002, 6: 2003, 7: 2004, 8: 2005, 9: 2006,\n","                         10: 2007, 11: 2008, 12: 2009, 13: 2010, 14: 2011,\n","                         15: 2012, 16: 2013, 17: 2014, 18: 2015, 19: 2016,\n","                         20: 2017})\n","\n","deflator['Year'] = yearList\n","\n","deflator.to_csv(in_path + 'original_COLI.csv')\n","# I didn't know why this work, but we have to export, and import the deflator sheet so the\n","# regression steps will work\n","deflator = pd.read_csv(in_path + 'original_COLI.csv', index_col = 0)\n","\n","# Generate regression grid\n","reg = pd.DataFrame(index = stateList, columns = [['Coefficient', 'Intercept', 'Rsquared']])\n","\n","for i in stateList:\n","  coefficient, intercept, r, p_value, std_err = stats.linregress(deflator['Year'], deflator[str(i)])\n","  reg.loc[i, 'Coefficient'] = coefficient\n","  reg.loc[i, 'Intercept'] = intercept\n","  reg.loc[i, 'Rsquared'] = r**2\n","  \n","reg.to_csv(in_path + 'reg.csv')\n","  \n","# # Generate prediction grid\n","# pred = pd.DataFrame(index = range (1978, 2019), columns = [['YEAR', 'STATEFIP', 'PRED_COLI']])  \n","# for y in range (1978, 2019):\n","#   line = pred[pred.index == y].copy()\n","#   line.name = y\n","#   #50 repetition, for 51 states, since we already have 1 line. \n","#   for s in range (0, 50): pred = pred.append(line)\n","  \n","# pred.reset_index(drop = True, inplace = True)    \n","\n","# i = 0\n","# for y in range (1978, 2019):\n","#   for s in stateList:\n","#     pred.loc[i, 'YEAR'] = y\n","#     pred.loc[i, 'STATEFIP'] = s\n","#     # If condition to use the original data for year in YearList\n","#     if y in yearList: pred.loc[i, 'PRED_COLI'] = deflator.loc[y, str(s)]\n","#     else: pred.loc[i, 'PRED_COLI'] = (reg.loc[s, 'Coefficient'])*y + (reg.loc[s, 'Intercept'])    \n","#     i = i + 1\n","    \n","# for i in range(0, len(pred)):\n","#   for y in range(1978, 2019):\n","#     pred[pred.YEAR == y].mean().YEAR\n","#     pred.iloc[i, 2] =  pred.iloc[i, 2]\n","\n","# # # Export deflator file\n","# # pred.to_csv(in_path + 'pred.csv')\n","\n","# # CAN'T MERGE DATAFRAME HERE DUE TO SOME CRYPTIC ERROR -- GO TO EXCEL AND MERGE IT -- FIGURE OUT LATER.\n","# # There must be something wrong about the datatype of 2 dataframes.\n","  \n","# # # Merge predicted COLI with CPI\n","# # pred = pd.merge(pred, cpi, on = ['YEAR'])\n","\n","# # # Normalize COLI with CPI\n","# # for i in range (len(pred)): pred.iloc[i, 2] = pred.iloc[i, 2]/pred.iloc[i, 3]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yTF32ok9o0JN","colab_type":"text"},"source":["# Data processor"]},{"cell_type":"markdown","metadata":{"id":"wktCmel8mGfg","colab_type":"text"},"source":["## year_d"]},{"cell_type":"code","metadata":{"id":"jpIt-4HBmY-0","colab_type":"code","outputId":"073c9943-0c44-4c5d-d62a-bacec36bb1de","executionInfo":{"status":"ok","timestamp":1567088555771,"user_tz":240,"elapsed":8262136,"user":{"displayName":"Sang Truong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCOvDUyD0IVxBIyFjvwy8Ym7mfJeHFjYHDJpFza1w=s64","userId":"12360713090073442907"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["import pandas as pd\n","import json\n","from collections import OrderedDict\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","in_path = 'gdrive/My Drive/Colab Notebooks/code/'\n","out_path = 'gdrive/My Drive/Colab Notebooks/oneYear/year_d/'\n","\n","# Import raw data state codes, color codes, and deflator\n","raw = pd.read_csv(in_path + \"raw.csv\")\n","\n","# Select data with HFLAG != 1 and then drop HFLAG\n","raw = raw[raw.HFLAG != 1]\n","raw = raw.drop(columns = ['HFLAG'])\n","\n","codeFirst_oneYear = pd.read_csv(in_path + \"codeFirst_oneYear.csv\", index_col = 0)\n","codeThird_oneYear = pd.read_csv(in_path + \"codeThird_oneYear.csv\", index_col = 0)\n","deflator = pd.read_csv(in_path + \"COLI.csv\")\n","\n","# Generate constants\n","stateList = [1,2,4,5,6,8,9,10,11,12,13,15,16,17,18,19,20,21,22,23,24,25,26,27,\n","             28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,44,45,46,47,48,49,\n","             50,51,53,54,55,56]\n","decile = [0.05,0.15,0.25,0.35,0.45,0.50,0.55,0.65,0.75,0.85,0.95]\n","value = ['','','','','','','','','','','','','','','','','','','','','','',\n","         '','','','','','','','','','','','','','','','','','','','','','',\n","         '','','','','','','']\n","\n","# Iterate through each year\n","for y in range(1978, 1979):\n","  \n","  # Generate result grid, decile-column\n","  result = pd.DataFrame(columns=stateList)\n","  for i in range(0, 11): result.loc[i] = value\n","  \n","  # Generate year dataframe\n","  year = raw[raw.YEAR == y]\n","  \n","  # Generate effective household size\n","  year.insert(0, 'SIZE', '')\n","  year.insert(0, 'EFFHSIZE','')\n","\n","  for i in range(0, len(year)):\n","    if year.loc[i, 'PERNUM'] == 1: year.loc[i, 'SIZE'] = 1\n","    elif year.loc[i, 'AGE'] > 16: year.loc[i, 'SIZE'] = 0.7\n","    else: year.loc[i, 'SIZE'] = 0.5\n","\n","  for i in range(0, len(year)):\n","    if year.loc[i, 'PERNUM'] == 1:\n","      j = 0\n","      year.loc[i, 'EFFHSIZE'] = year.loc[i, 'SIZE']\n","    else:\n","      j = j + 1\n","      year.loc[i-j, 'EFFHSIZE'] = year.loc[i-j, 'EFFHSIZE'] + year.loc[i, 'SIZE']\n","\n","  # Eliminate observations that has PERNUM != 1\n","  person = year[year.PERNUM == 1]\n","  person = person.drop(columns = ['PERNUM'])\n","  \n","  # Merge 2 file: for raw, every row that has STATEFIP and YEAR match with \n","  # that row in deflator will get the same deflator value.\n","  person = pd.merge(person, deflator, on = [\"YEAR\", \"STATEFIP\"])\n","  \n","  # Generate deflated household income column\n","  person.insert(0, 'DHHINCOME', '')\n","  \n","  # Normalize HHINCOME to DHHINCOME (deflate with COLI and EFFSIZE)\n","  for i in range (0, len(person)):\n","    person.loc[i, 'DHHINCOME'] = person.loc[i, 'HHINCOME']/(person.loc[i, 'DEFLATOR']*person.loc[i, 'EFFHSIZE'])\n","  \n","  # Iterate through each state\n","  c = 0\n","  for i in stateList:\n","    # Generate state dataframe\n","    state = person[person.STATEFIP == i]\n","    state = state.reset_index(drop = True)\n","\n","    # Sort state dataframe by DHHINCOME\n","    state = state.sort_values('DHHINCOME')\n","    \n","    # Calculate cumulated weight and Percentage\n","    state.insert(0, 'CUMWT', '')\n","    state.insert(0, 'PERCENT', '')\n","    state.loc[0, 'CUMWT'] = state.loc[0, 'ASECWTH']\n","    state.loc[0, 'PERCENT'] = state.loc[0, 'CUMWT']/(state.sum().ASECWTH)\n","    for i in range (1, len(state)):\n","      state.loc[i, 'CUMWT'] = state.loc[i-1, 'CUMWT'] + state.loc[i, 'ASECWTH']\n","      state.loc[i, 'PERCENT'] = state.loc[i, 'CUMWT']/(state.sum().ASECWTH)\n","    \n","    # Calculate decile\n","    r = 0\n","    for d in decile:\n","      for i in range (0, len(state)):\n","        if (d < state.loc[i, 'PERCENT']):\n","          result.iloc[r,c] = state.loc[i, 'DHHINCOME']\n","          r = r + 1\n","          break\n","    c = c + 1\n","    \n","  # Transpose result table: column-decile\n","  result = result.transpose()\n","\n","  # Type casting result.index (type casting STATEFIP) to integer\n","  result.index = result.index.map(int)\n","\n","  # Merge state dataframe with code dataframe\n","  result = pd.merge(codeFirst_oneYear, result, left_index = True, right_index = True)\n","  result = pd.merge(result, codeThird_oneYear, left_index = True, right_index = True)\n","\n","  # Compute state population and normalized state population\n","  result.insert(0, 'POP','')\n","  for i in stateList:\n","    state = year[year.STATEFIP == i]\n","    result.loc[i, 'POP'] = state.sum().ASECWT\n","\n","  result.insert(0, 'NORMPOP', '')\n","  for i in stateList:\n","    result.loc[i, 'NORMPOP'] = round(result.loc[i, 'POP']/(result['POP'].min()))\n","\n","  # Replicate each state's dataline with its respected replication number\n","  for i in stateList:\n","    rep = result.loc[i,'NORMPOP'] - 1\n","    rep = int(rep)\n","    line = result[result.index == i].copy()\n","    line.name = i\n","    line.loc[i, 'Label'] = ''\n","    for i in range(0,rep): result = result.append(line)\n","          \n","  result = result.drop(columns = ['POP', 'NORMPOP'])\n","        \n","  # Sort the result by median\n","  result = result.sort_values(by=['5'], ascending = True)\n","\n","  # Rename index column and role\n","  result = result.rename(index = str, columns = {0: \"5p\", 1: \"15p\", 2: \"25p\", 3: \"35p\", 4: \"45p\", 5: \"50p\",\n","                                                6: \"55p\", 7: \"65p\", 8: \"75p\", 9: \"85p\", 10: \"95p\"})\n","\n","  # Export result grid  \n","  result.to_csv(out_path + str(y) + '_d.csv')\n","\n","  # Convert dataframe to JSON\n","  result = result.to_json(orient = 'records')\n","  result = json.loads(result, object_pairs_hook = OrderedDict)\n","\n","  # Make JSON format readable\n","  result = json.dumps(result, indent = 4, sort_keys = False)\n","\n","  # Save JSON to text format\n","  with open(out_path + str(y) + '_d.txt', 'w') as f:\n","    f.writelines(result)\n","\n","  # Glue data with html environment\n","  filenames = [in_path + 'first_d_oneYear.txt', out_path + str(y) + '_d.txt',\n","              in_path + 'third.txt']\n","  with open(out_path + str(y) + '_d.html', 'w') as outfile:\n","    for i in filenames:\n","      with open (i) as infile:\n","        outfile.write(infile.read())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","  self.obj[item] = s\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"BLZUPqLumKgz","colab_type":"text"},"source":["## year_p\n","\n","There are 4 differences between d_files and p_files:\n","\n","*   Deciles\n","*   Loop to construct result grid sheet (0 to 98 instead of 0 to 11)\n","*   Use first_p instead of first_d (look at pCodeGenerator excel file for detail about p_code generator)\n","*   out_path: use year_p_gsp_data instead of year_d_gsp_data\n","*   Change name when export data"]},{"cell_type":"code","metadata":{"id":"hrjWsL9mmaD3","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import json\n","from collections import OrderedDict\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","in_path = 'gdrive/My Drive/Colab Notebooks/code/'\n","out_path = 'gdrive/My Drive/Colab Notebooks/oneYear/year_p/'\n","\n","# Import raw data state codes, color codes, and deflator\n","raw = pd.read_csv(in_path + \"raw.csv\")\n","codeFirst_oneYear = pd.read_csv(in_path + \"codeFirst_oneYear.csv\", index_col = 0)\n","codeThird_oneYear = pd.read_csv(in_path + \"codeThird_oneYear.csv\", index_col = 0)\n","deflator = pd.read_csv(in_path + \"COLI.csv\")\n","\n","# Generate constants\n","stateList = [1,2,4,5,6,8,9,10,11,12,13,15,16,17,18,19,20,21,22,23,24,25,26,27,\n","             28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,44,45,46,47,48,49,\n","             50,51,53,54,55,56]\n","decile = [0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1,0.11,0.12,0.13,0.14,0.15,\n","          0.16,0.17,0.18,0.19,0.2,0.21,0.22,0.23,0.24,0.25,0.26,0.27,0.28,0.29,\n","          0.3,0.31,0.32,0.33,0.34,0.35,0.36,0.37,0.38,0.39,0.4,0.41,0.42,0.43,\n","          0.44,0.45,0.46,0.47,0.48,0.49,0.5,0.51,0.52,0.53,0.54,0.55,0.56,0.57,\n","          0.58,0.59,0.6,0.61,0.62,0.63,0.64,0.65,0.66,0.67,0.68,0.69,0.7,0.71,\n","          0.72,0.73,0.74,0.75,0.76,0.77,0.78,0.79,0.8,0.81,0.82,0.83,0.84,0.85,\n","          0.86,0.87,0.88,0.89,0.9,0.91,0.92,0.93,0.94,0.95,0.96,0.97,0.98,0.99]\n","value = ['','','','','','','','','','','','','','','','','','','','','','',\n","         '','','','','','','','','','','','','','','','','','','','','','',\n","         '','','','','','','']\n","\n","# Iterate through each year\n","for y in range(1978, 1979):\n","  \n","  # Generate result grid, decile-column\n","  result = pd.DataFrame(columns = stateList)\n","  for i in range(0, 98): result.loc[i] = value\n","  \n","  # Generate year dataframe\n","  year = raw[raw.YEAR == y]\n","  \n","  # Eliminate observations that has PERNUM != 1\n","  person = year[year.PERNUM == 1]\n","  \n","  # Merge 2 file: for raw, every row that has STATEFIP and YEAR match with \n","  # that row in deflator will get the same deflator value.\n","  person = pd.merge(person, deflator, on = [\"YEAR\",\"STATEFIP\"])\n","  \n","  # Rearrange culumns order\n","  person = person[['YEAR', 'ASECWTH', 'STATEFIP', 'HHINCOME', 'PERNUM', \n","                   'ASECWT','DEFLATOR','SEX','RACE','HISPAN','EDUC']]\n","  \n","  # Generate deflated household income column\n","  person.insert(7, 'DHHINCOME', '')\n","  \n","  # Iterate through the entire 'person' to calculate deflated income\n","  for i in range (0, len(person)):\n","    person.iloc[i, 7] = person.iloc[i, 3]/person.iloc[i, 6]\n","  \n","  # Sort the remainded observation by STATEFIP\n","  person.sort_values('STATEFIP')\n","  \n","  # Iterate through each state\n","  c = 0\n","  for i in stateList:\n","    # Generate state dataframe\n","    state = person[person.STATEFIP == i]\n","    \n","    # Sort state dataframe by HHINCOME\n","    state = state.sort_values('HHINCOME')\n","    \n","    # Calculate cumulated weight and Percentage\n","    state.insert(8, 'CUMWT', '')\n","    state.insert(9, 'PERCENT', '')\n","    state.iloc[0, 8] = state.iloc[0, 1]\n","    state.iloc[0, 9] = state.iloc[0, 8]/(state.sum().ASECWT)\n","    for i in range (1, len(state)):\n","      state.iloc[i, 8] = state.iloc[i-1, 8] + state.iloc[i, 1]\n","      state.iloc[i, 9] = state.iloc[i, 8]/(state.sum().ASECWT)\n","    \n","    # Calculate decile\n","    r = 0\n","    for d in decile:\n","      for i in range (0, len(state)):\n","        if (d < state.iloc[i, 9]):\n","          result.iloc[r,c] = state.iloc[i, 7]\n","          r = r + 1\n","          break\n","    c = c + 1\n","    \n","  # Transpose result table: column-decile\n","  result = result.transpose()\n","\n","  # Type casting result.index (type casting STATEFIP) to integer\n","  result.index = result.index.map(int)\n","\n","  # Merge state dataframe with code dataframe\n","  result = pd.merge(codeFirst_oneYear, result, left_index = True, right_index = True)\n","  result = pd.merge(result, codeThird_oneYear, left_index = True, right_index = True)\n","\n","  result.insert(101, 'POP','')\n","  r = 0\n","  for i in stateList:\n","    state = year[year.STATEFIP == i]\n","    result.iloc[r, 101] = state.sum().ASECWT\n","    r = r + 1\n","\n","  result.insert(102, 'NORMPOP', '')\n","  for i in range(0, len(result)):\n","    result.iloc[i, 102] = round(result.iloc[i, 101]/(result['POP'].min()))\n","\n","  for i in stateList:\n","    rep = result.loc[int(i),'NORMPOP'] - 1\n","    rep = int(rep)\n","    # The following statement need .copy() at the end for explicit reason\n","    # More information: https://www.dataquest.io/blog/settingwithcopywarning/\n","    line = result[result.index == i].copy()\n","    line.name = i\n","    line.iloc[0, 99] = ''\n","    for i in range(0,rep): result = result.append(line)\n","        \n","  # result.to_csv(out_path+str(y)+'withPop.csv')\n","  result = result.drop(columns = ['POP', 'NORMPOP'])\n","      \n","  # Sort the result by median\n","  result = result.sort_values(48, ascending = True)\n","\n","  # Rename index column and role\n","  result = result.rename(index = str, columns = {0: \"2p\", 1: \"3p\", 2: \"4p\", 3: \"5p\",\n","                                                 4: \"6p\", 5: \"7p\", 6: \"8p\", 7: \"9p\",\n","                                                 8: \"10p\", 9: \"11p\", 10: \"12p\",\n","                                                 11: \"13p\", 12: \"14p\", 13: \"15p\",\n","                                                 14: \"16p\", 15: \"17p\", 16: \"18p\",\n","                                                 17: \"19p\", 18: \"20p\", 19: \"21p\",\n","                                                 20: \"22p\", 21: \"23p\", 22: \"24p\",\n","                                                 23: \"25p\", 24: \"26p\", 25: \"27p\",\n","                                                 26: \"28p\", 27: \"29p\", 28: \"30p\",\n","                                                 29: \"31p\", 30: \"32p\", 31: \"33p\",\n","                                                 32: \"34p\", 33: \"35p\", 34: \"36p\",\n","                                                 35: \"37p\", 36: \"38p\", 37: \"39p\",\n","                                                 38: \"40p\", 39: \"41p\", 40: \"42p\",\n","                                                 41: \"43p\", 42: \"44p\", 43: \"45p\",\n","                                                 44: \"46p\", 45: \"47p\", 46: \"48p\",\n","                                                 47: \"49p\", 48: \"50p\", 49: \"51p\",\n","                                                 50: \"52p\", 51: \"53p\", 52: \"54p\",\n","                                                 53: \"55p\", 54: \"56p\", 55: \"57p\",\n","                                                 56: \"58p\", 57: \"59p\", 58: \"60p\",\n","                                                 59: \"61p\", 60: \"62p\", 61: \"63p\",\n","                                                 62: \"64p\", 63: \"65p\", 64: \"66p\",\n","                                                 65: \"67p\", 66: \"68p\", 67: \"69p\",\n","                                                 68: \"70p\", 69: \"71p\", 70: \"72p\",\n","                                                 71: \"73p\", 72: \"74p\", 73: \"75p\",\n","                                                 74: \"76p\", 75: \"77p\", 76: \"78p\",\n","                                                 77: \"79p\", 78: \"80p\", 79: \"81p\",\n","                                                 80: \"82p\", 81: \"83p\", 82: \"84p\",\n","                                                 83: \"85p\", 84: \"86p\", 85: \"87p\",\n","                                                 86: \"88p\", 87: \"89p\", 88: \"90p\",\n","                                                 89: \"91p\", 90: \"92p\", 91: \"93p\",\n","                                                 92: \"94p\", 93: \"95p\", 94: \"96p\",\n","                                                 95: \"97p\", 96: \"98p\", 97: \"99p\"})\n","  \n","  result.to_csv(out_path+str(y) + '_p.csv')\n","\n","  # Convert dataframe to JSON\n","  result = result.to_json(orient = 'records')\n","  result = json.loads(result, object_pairs_hook = OrderedDict)\n","\n","  # Make JSON format readable\n","  result = json.dumps(result, indent = 4, sort_keys = False)\n","\n","  # Save JSON to text format\n","  with open(out_path + str(y) + '_p.txt', 'w') as f:\n","    f.writelines(result)\n","\n","  # Glue data with html environment\n","  filenames = [in_path + 'first_p_oneYear.txt', out_path + str(y) + '_p.txt',\n","               in_path + 'third.txt']\n","  with open(out_path + str(y) + '_p.html', 'w') as outfile:\n","    for i in filenames:\n","      with open (i) as infile:\n","        outfile.write(infile.read())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k-SjerHFco5M","colab_type":"text"},"source":["## state_d"]},{"cell_type":"code","metadata":{"id":"NAWX38PvNgt4","colab_type":"code","outputId":"c4b23688-a898-4718-8c58-69eff0503760","executionInfo":{"status":"ok","timestamp":1562105275758,"user_tz":240,"elapsed":2281205,"user":{"displayName":"Sang Truong","photoUrl":"https://lh6.googleusercontent.com/-jVigpXBwjq8/AAAAAAAAAAI/AAAAAAAABMM/Ws6jke_7DUc/s64/photo.jpg","userId":"12360713090073442907"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import pandas as pd\n","import json\n","from collections import OrderedDict\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","in_path = 'gdrive/My Drive/Colab Notebooks/code/'\n","out_path = 'gdrive/My Drive/Colab Notebooks/oneState/state_d/'\n","\n","# Import raw data state codes, color codes, and deflator\n","raw = pd.read_csv(in_path + \"raw.csv\")\n","codeFirst_oneState = pd.read_csv(in_path + \"codeFirst_oneState.csv\", index_col = 0)\n","codeThird_oneState = pd.read_csv(in_path + \"codeThird_oneState.csv\", index_col = 0)\n","deflator = pd.read_csv(in_path +\"COLI.csv\")\n","\n","# Select data with HFLAG != 1 and then drop HFLAG\n","raw = raw[raw.HFLAG != 1]\n","raw = raw.drop(columns = ['HFLAG'])\n","\n","# Generate constants\n","stateList = [1,2,4,5,6,8,9,10,11,12,13,15,16,17,18,19,20,21,22,23,24,25,26,27,\n","             28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,44,45,46,47,48,49,\n","             50,51,53,54,55,56]\n","\n","# stateList = [12]\n","\n","decile = [0.05,0.15,0.25,0.35,0.45,0.50,0.55,0.65,0.75,0.85,0.95]\n","value = ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n","         '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n","         '', '', '', '', '']\n","yearList = [1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988,\n","            1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999,\n","            2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010,\n","            2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018]\n","\n","# Iterate through each state\n","for s in stateList:\n","  \n","  # Generate result grid, decile-column\n","  result = pd.DataFrame(columns = yearList)\n","  for i in range(0, 11): result.loc[i] = value\n","  \n","  # Generate state dataframe\n","  state = raw[raw.STATEFIP == s]\n","\n","  # Eliminate observations that has PERNUM != 1\n","  person = state[state.PERNUM == 1]\n","  \n","  # Merge 2 file: for raw, every row that has STATEFIP and YEAR match with \n","  # that row in deflator will get the same deflator value.\n","  person = pd.merge(person, deflator, on = [\"YEAR\",\"STATEFIP\"])\n","  \n","  # Rearrange culumns order\n","  person = person[['YEAR', 'ASECWTH', 'STATEFIP', 'HHINCOME', 'PERNUM', \n","                   'ASECWT','DEFLATOR','SEX','RACE','HISPAN','EDUC']]\n","  \n","  # Generate deflated household income column\n","  person.insert(7, 'DHHINCOME', '')\n","  \n","  # Iterate through the entire 'person' to calculate deflated income\n","  for i in range (0, len(person)):\n","    person.iloc[i, 7] = person.iloc[i, 3]/person.iloc[i, 6]\n","  \n","  # Sort the remainded observation by YEAR\n","  person.sort_values('YEAR')\n","  \n","  # Iterate through each year\n","  c = 0\n","  for i in yearList:\n","    # Generate year dataframe\n","    year = person[person.YEAR == i]\n","    \n","    # Sort year dataframe by HHINCOME\n","    year = year.sort_values('HHINCOME')\n","    \n","    # Calculate cumulated weight and Percentage\n","    year.insert(8, 'CUMWT', '')\n","    year.insert(9, 'PERCENT', '')\n","    year.iloc[0, 8] = year.iloc[0, 1]\n","    year.iloc[0, 9] = year.iloc[0, 8]/(year.sum().ASECWT)\n","    for i in range (1, len(year)):\n","      year.iloc[i, 8] = year.iloc[i-1, 8] + year.iloc[i, 1]\n","      year.iloc[i, 9] = year.iloc[i, 8]/(year.sum().ASECWT)\n","    \n","    # Calculate decile\n","    r = 0\n","    for d in decile:\n","      for i in range (0, len(year)):\n","        if (d < year.iloc[i, 9]):\n","          result.iloc[r,c] = year.iloc[i, 7]\n","          r = r + 1\n","          break\n","    c = c + 1\n","    \n","  # Transpose result table: column-decile\n","  result = result.transpose()\n","\n","  # Type casting result.index (type casting YEAR) to integer\n","  result.index = result.index.map(int)\n","\n","  # Merge state dataframe with code dataframe\n","  result = pd.merge(codeFirst_oneState, result, left_index = True, right_index = True)\n","  result = pd.merge(result, codeThird_oneState, left_index = True, right_index = True)\n","\n","  result.insert(14, 'POP','')\n","  r = 0\n","  for i in yearList:\n","    year = state[state.YEAR == i]\n","    result.iloc[r, 14] = year.sum().ASECWT\n","    r = r + 1\n","\n","  result.insert(15, 'NORMPOP', '')\n","  for i in range(0, len(result)):\n","    result.iloc[i, 15] = round(10*(result.iloc[i, 14])/(result['POP'].min()))\n","#     result.iloc[i, 15] = result.iloc[i, 14]/(result['POP'].min())\n","  for i in yearList:\n","    rep = result.loc[int(i),'NORMPOP'] - 1\n","    rep = int(rep)\n","    # The following statement need .copy() at the end for explicit reason\n","    # More information: https://www.dataquest.io/blog/settingwithcopywarning/\n","    line = result[result.index == i].copy()\n","    line.name = i\n","    # Remove the name of the state (so that the name does not repeat too many time)\n","    line.iloc[0, 12] = ''\n","    for i in range(0,rep): result = result.append(line)\n","        \n","#   # result.to_csv(out_path+str(y)+'withPop.csv')\n","  result = result.drop(columns = ['POP', 'NORMPOP'])\n","      \n","  # Sort the result by year\n","  result = result.sort_values(\"Year\", ascending = True)\n","\n","  # Rename index column and role\n","  result = result.rename(index = str, columns = {0: \"5p\", 1: \"15p\", 2: \"25p\",\n","                                                 3: \"35p\", 4: \"45p\", 5: \"50p\",\n","                                                 6: \"55p\", 7: \"65p\", 8: \"75p\",\n","                                                 9: \"85p\", 10: \"95p\"})\n","  \n","  result.to_csv(out_path+str(s) + '_d.csv')\n","\n","  # Convert dataframe to JSON\n","  result = result.to_json(orient = 'records')\n","  result = json.loads(result, object_pairs_hook = OrderedDict)\n","\n","  # Make JSON format readable\n","  result = json.dumps(result, indent = 4, sort_keys = False)\n","\n","  # Save JSON to text format\n","  with open(out_path + str(s) + '_d.txt', 'w') as f:\n","    f.writelines(result)\n","\n","  # Glue data with html environment\n","  filenames = [in_path + 'first_d_oneState.txt', out_path + str(s) + '_d.txt',\n","               in_path + 'third.txt']\n","  with open(out_path + str(s) + '_d.html', 'w') as outfile:\n","    for i in filenames:\n","      with open (i) as infile:\n","        outfile.write(infile.read())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"skDocBwlc6js","colab_type":"text"},"source":["## state_p"]},{"cell_type":"code","metadata":{"id":"fxIlCwJ5c53b","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import json\n","from collections import OrderedDict\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","in_path = 'gdrive/My Drive/Colab Notebooks/code/'\n","out_path = 'gdrive/My Drive/Colab Notebooks/oneState/state_p/'\n","\n","# Import raw data state codes, color codes, and deflator\n","raw = pd.read_csv(in_path + \"raw.csv\")\n","codeFirst_oneState = pd.read_csv(in_path + \"codeFirst_oneState.csv\", index_col = 0)\n","codeThird_oneState = pd.read_csv(in_path + \"codeThird_oneState.csv\", index_col = 0)\n","deflator = pd.read_csv(in_path + \"COLI.csv\")\n","\n","# Generate constants\n","stateList = [1,2,4,5,6,8,9,10,11,12,13,15,16,17,18,19,20,21,22,23,24,25,26,27,\n","             28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,44,45,46,47,48,49,\n","             50,51,53,54,55,56]\n","\n","# stateList = [11]\n","\n","decile = [0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1,0.11,0.12,0.13,0.14,0.15,\n","          0.16,0.17,0.18,0.19,0.2,0.21,0.22,0.23,0.24,0.25,0.26,0.27,0.28,0.29,\n","          0.3,0.31,0.32,0.33,0.34,0.35,0.36,0.37,0.38,0.39,0.4,0.41,0.42,0.43,\n","          0.44,0.45,0.46,0.47,0.48,0.49,0.5,0.51,0.52,0.53,0.54,0.55,0.56,0.57,\n","          0.58,0.59,0.6,0.61,0.62,0.63,0.64,0.65,0.66,0.67,0.68,0.69,0.7,0.71,\n","          0.72,0.73,0.74,0.75,0.76,0.77,0.78,0.79,0.8,0.81,0.82,0.83,0.84,0.85,\n","          0.86,0.87,0.88,0.89,0.9,0.91,0.92,0.93,0.94,0.95,0.96,0.97,0.98,0.99]\n","\n","value = ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n","         '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n","         '', '', '', '', '']\n","\n","yearList = [1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988,\n","            1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999,\n","            2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010,\n","            2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018]\n","\n","# Iterate through each state\n","for s in stateList:\n","  \n","  # Generate result grid, decile-column\n","  result = pd.DataFrame(columns = yearList)\n","  for i in range(0, 98): result.loc[i] = value\n","  \n","  # Generate state dataframe\n","  state = raw[raw.STATEFIP == s]\n","\n","  # Eliminate observations that has PERNUM != 1\n","  person = state[state.PERNUM == 1]\n","  \n","  # Merge 2 file: for raw, every row that has STATEFIP and YEAR match with \n","  # that row in deflator will get the same deflator value.\n","  person = pd.merge(person, deflator, on = [\"YEAR\",\"STATEFIP\"])\n","  \n","  # Rearrange culumns order\n","  person = person[['YEAR', 'ASECWTH', 'STATEFIP', 'HHINCOME', 'PERNUM', \n","                   'ASECWT','DEFLATOR','SEX','RACE','HISPAN','EDUC']]\n","  \n","  # Generate deflated household income column\n","  person.insert(7, 'DHHINCOME', '')\n","  \n","  # Iterate through the entire 'person' to calculate deflated income\n","  for i in range (0, len(person)):\n","    person.iloc[i, 7] = person.iloc[i, 3]/person.iloc[i, 6]\n","  \n","  # Sort the remainded observation by YEAR\n","  person.sort_values('YEAR')\n","  \n","  # Iterate through each year\n","  c = 0\n","  for i in yearList:\n","    # Generate year dataframe\n","    year = person[person.YEAR == i]\n","    \n","    # Sort year dataframe by HHINCOME\n","    year = year.sort_values('HHINCOME')\n","    \n","    # Calculate cumulated weight and Percentage\n","    year.insert(8, 'CUMWT', '')\n","    year.insert(9, 'PERCENT', '')\n","    year.iloc[0, 8] = year.iloc[0, 1]\n","    year.iloc[0, 9] = year.iloc[0, 8]/(year.sum().ASECWT)\n","    for i in range (1, len(year)):\n","      year.iloc[i, 8] = year.iloc[i-1, 8] + year.iloc[i, 1]\n","      year.iloc[i, 9] = year.iloc[i, 8]/(year.sum().ASECWT)\n","    \n","    # Calculate decile\n","    r = 0\n","    for d in decile:\n","      for i in range (0, len(year)):\n","        if (d < year.iloc[i, 9]):\n","          result.iloc[r,c] = year.iloc[i, 7]\n","          r = r + 1\n","          break\n","    c = c + 1\n","    \n","  # Transpose result table: column-decile\n","  result = result.transpose()\n","\n","  # Type casting result.index (type casting YEAR) to integer\n","  result.index = result.index.map(int)\n","\n","  # Merge state dataframe with code dataframe\n","  result = pd.merge(codeFirst_oneState, result, left_index = True, right_index = True)\n","  result = pd.merge(result, codeThird_oneState, left_index = True, right_index = True)\n","\n","  result.insert(14, 'POP','')\n","  r = 0\n","  for i in yearList:\n","    year = state[state.YEAR == i]\n","    result.iloc[r, 14] = year.sum().ASECWT\n","    r = r + 1\n","\n","  result.insert(15, 'NORMPOP', '')\n","  for i in range(0, len(result)):\n","    result.iloc[i, 15] = round(result.iloc[i, 14]/(result['POP'].min()))\n","\n","  for i in yearList:\n","    rep = result.loc[int(i),'NORMPOP'] - 1\n","    rep = int(rep)\n","    # The following statement need .copy() at the end for explicit reason\n","    # More information: https://www.dataquest.io/blog/settingwithcopywarning/\n","    line = result[result.index == i].copy()\n","    line.name = i\n","    # Remove the name of the state (so that the name does not repeat too many time)\n","    line.iloc[0, 12] = ''\n","    for i in range(0,rep): result = result.append(line)\n","        \n","#   # result.to_csv(out_path+str(y)+'withPop.csv')\n","  result = result.drop(columns = ['POP', 'NORMPOP'])\n","      \n","  # Sort the result by year\n","  result = result.sort_values(\"Year\", ascending = True)\n","\n","  # Rename index column and role\n","  result = result.rename(index = str, columns = {0: \"2p\", 1: \"3p\", 2: \"4p\", 3: \"5p\",\n","                                                 4: \"6p\", 5: \"7p\", 6: \"8p\", 7: \"9p\",\n","                                                 8: \"10p\", 9: \"11p\", 10: \"12p\",\n","                                                 11: \"13p\", 12: \"14p\", 13: \"15p\",\n","                                                 14: \"16p\", 15: \"17p\", 16: \"18p\",\n","                                                 17: \"19p\", 18: \"20p\", 19: \"21p\",\n","                                                 20: \"22p\", 21: \"23p\", 22: \"24p\",\n","                                                 23: \"25p\", 24: \"26p\", 25: \"27p\",\n","                                                 26: \"28p\", 27: \"29p\", 28: \"30p\",\n","                                                 29: \"31p\", 30: \"32p\", 31: \"33p\",\n","                                                 32: \"34p\", 33: \"35p\", 34: \"36p\",\n","                                                 35: \"37p\", 36: \"38p\", 37: \"39p\",\n","                                                 38: \"40p\", 39: \"41p\", 40: \"42p\",\n","                                                 41: \"43p\", 42: \"44p\", 43: \"45p\",\n","                                                 44: \"46p\", 45: \"47p\", 46: \"48p\",\n","                                                 47: \"49p\", 48: \"50p\", 49: \"51p\",\n","                                                 50: \"52p\", 51: \"53p\", 52: \"54p\",\n","                                                 53: \"55p\", 54: \"56p\", 55: \"57p\",\n","                                                 56: \"58p\", 57: \"59p\", 58: \"60p\",\n","                                                 59: \"61p\", 60: \"62p\", 61: \"63p\",\n","                                                 62: \"64p\", 63: \"65p\", 64: \"66p\",\n","                                                 65: \"67p\", 66: \"68p\", 67: \"69p\",\n","                                                 68: \"70p\", 69: \"71p\", 70: \"72p\",\n","                                                 71: \"73p\", 72: \"74p\", 73: \"75p\",\n","                                                 74: \"76p\", 75: \"77p\", 76: \"78p\",\n","                                                 77: \"79p\", 78: \"80p\", 79: \"81p\",\n","                                                 80: \"82p\", 81: \"83p\", 82: \"84p\",\n","                                                 83: \"85p\", 84: \"86p\", 85: \"87p\",\n","                                                 86: \"88p\", 87: \"89p\", 88: \"90p\",\n","                                                 89: \"91p\", 90: \"92p\", 91: \"93p\",\n","                                                 92: \"94p\", 93: \"95p\", 94: \"96p\",\n","                                                 95: \"97p\", 96: \"98p\", 97: \"99p\"})\n","  \n","  result.to_csv(out_path+str(s) + '_p.csv')\n","\n","  # Convert dataframe to JSON\n","  result = result.to_json(orient = 'records')\n","  result = json.loads(result, object_pairs_hook = OrderedDict)\n","\n","  # Make JSON format readable\n","  result = json.dumps(result, indent = 4, sort_keys = False)\n","\n","  # Save JSON to text format\n","  with open(out_path + str(s) + '_p.txt', 'w') as f:\n","    f.writelines(result)\n","\n","  # Glue data with html environment\n","  filenames = [in_path + 'first_p_oneState.txt', out_path + str(s) + '_p.txt',\n","               in_path + 'third.txt']\n","  with open(out_path + str(s) + '_p.html', 'w') as outfile:\n","    for i in filenames:\n","      with open (i) as infile:\n","        outfile.write(infile.read())\n","        \n","        #Adjust max income \n","        #Adjust household size"],"execution_count":0,"outputs":[]}]}