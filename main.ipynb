{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "k-SjerHFco5M",
        "skDocBwlc6js"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sangttruong/IncomeVis/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr1e3YZuRikN",
        "colab_type": "text"
      },
      "source": [
        "# Visualizing Income Inequality in the United Stated\n",
        "\n",
        "Author: Sang Truong and Dr. Humberto Barreto, Department of Economics and Management\n",
        "\n",
        "DePauw University, Greencastle, Indiana, 46135, Summer 2019\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4MJifrArn_e",
        "colab_type": "text"
      },
      "source": [
        "This notebook records all important steps to transform, compress, and visualize raw from IPUMS-CPS.\n",
        "\n",
        "Before starting to work with the data, we import some important library, such as pandas for data manipulation and analysis, numpy for scientific computing, sklearn for statistical analysis. we also mount my Google Drive to Google Colab so that all of my analyses are conduct online."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhyEoROCRflY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "from collections import OrderedDict\n",
        "from google.colab import drive\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "in_path = 'gdrive/My Drive/Colab Notebooks/IncomeVis2019/input/'\n",
        "out_path = 'gdrive/My Drive/Colab Notebooks/IncomeVis2019/output/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qX4F3Ltva5iT",
        "colab_type": "text"
      },
      "source": [
        "# Section 1. Deflator generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWG1_wkIkayo",
        "colab_type": "text"
      },
      "source": [
        "100 dollars last 10 years is not equal to 100 dollars today due to inflation. To compare incomes overtime, we need to converge them to the same unit (specifically, in this analysi we use 2018 dollars). We achieve this goal by using Consumer Price Index (CPI) deflator.\n",
        "\n",
        "However, even after account for inflation, it still does not make sense to compare income of a person in Indiana with a person in California, simply because it is significantly more expensive to live in California. To account for this difference, we deflate income with Cost of Living Index (COLI) deflator.\n",
        "\n",
        "The final deflator is the product of 2 above index. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVqRN-nSQzAQ",
        "colab_type": "text"
      },
      "source": [
        "## 1.1. Cost Of Living Index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6-YA9MEl14c",
        "colab_type": "text"
      },
      "source": [
        "COLI raw data can be downloaded from IPUMS-USA: https://usa.ipums.org/usa. Below, we first 10 rows of our raw data and its summary statistics. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj8af5pq6wHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import raw COLI\n",
        "raw_COLI = pd.read_csv(in_path + \"raw_COLI.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaPpAmXUmn3d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "8f3c52b8-12c0-465e-c4e0-38f9f76aafa6"
      },
      "source": [
        "raw_COLI.head(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>HHWT</th>\n",
              "      <th>STATEFIP</th>\n",
              "      <th>RENTGRS</th>\n",
              "      <th>RELATE</th>\n",
              "      <th>RELATED</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1970</td>\n",
              "      <td>100</td>\n",
              "      <td>25</td>\n",
              "      <td>168</td>\n",
              "      <td>1</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1970</td>\n",
              "      <td>100</td>\n",
              "      <td>25</td>\n",
              "      <td>168</td>\n",
              "      <td>2</td>\n",
              "      <td>201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1970</td>\n",
              "      <td>100</td>\n",
              "      <td>25</td>\n",
              "      <td>168</td>\n",
              "      <td>3</td>\n",
              "      <td>301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1970</td>\n",
              "      <td>100</td>\n",
              "      <td>25</td>\n",
              "      <td>168</td>\n",
              "      <td>3</td>\n",
              "      <td>301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1970</td>\n",
              "      <td>100</td>\n",
              "      <td>25</td>\n",
              "      <td>168</td>\n",
              "      <td>3</td>\n",
              "      <td>301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1970</td>\n",
              "      <td>100</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1970</td>\n",
              "      <td>100</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1970</td>\n",
              "      <td>100</td>\n",
              "      <td>25</td>\n",
              "      <td>133</td>\n",
              "      <td>1</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1970</td>\n",
              "      <td>100</td>\n",
              "      <td>25</td>\n",
              "      <td>133</td>\n",
              "      <td>2</td>\n",
              "      <td>201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1970</td>\n",
              "      <td>100</td>\n",
              "      <td>25</td>\n",
              "      <td>133</td>\n",
              "      <td>3</td>\n",
              "      <td>301</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   YEAR  HHWT  STATEFIP  RENTGRS  RELATE  RELATED\n",
              "0  1970   100        25      168       1      101\n",
              "1  1970   100        25      168       2      201\n",
              "2  1970   100        25      168       3      301\n",
              "3  1970   100        25      168       3      301\n",
              "4  1970   100        25      168       3      301\n",
              "5  1970   100        25        0       1      101\n",
              "6  1970   100        25        0       3      301\n",
              "7  1970   100        25      133       1      101\n",
              "8  1970   100        25      133       2      201\n",
              "9  1970   100        25      133       3      301"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg54cZvPmfXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate constants for COLI\n",
        "stateList = [1,2,4,5,6,8,9,10,11,12,13,15,16,17,18,19,20,21,22,23,24,25,26,27,\n",
        "             28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,44,45,46,47,48,49,\n",
        "             50,51,53,54,55,56]\n",
        "\n",
        "yearList = [1970, 1980, 1990, 2000, 2001, 2002, 2003, 2004, 2005, 2006,\n",
        "            2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f84Dcpub34pP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Eliminate RENTGRS = 0\n",
        "raw_COLI = raw_COLI[raw_COLI.RENTGRS != 0]\n",
        "\n",
        "# Select the household head\n",
        "raw_COLI = raw_COLI[raw_COLI.RELATE == 1]\n",
        "raw_COLI = raw_COLI.drop(columns = ['RELATE'])\n",
        "\n",
        "# Generate COLI grid\n",
        "COLI = pd.DataFrame(columns = yearList, index = stateList)\n",
        "\n",
        "# Iterate through each year in yearList\n",
        "for y in yearList:\n",
        "  year = raw_COLI[raw_COLI.YEAR == y]\n",
        "\n",
        "  # Iterate through each state\n",
        "  COLI[y] = year.groupby(year['STATEFIP'])['RENTGRS'].median()\n",
        "\n",
        "# Compute COLI\n",
        "COLI = 0.44*COLI + 0.56\n",
        "\n",
        "COLI = COLI.T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYeKzh1PJbXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate regression grid\n",
        "reg = pd.DataFrame(index = stateList, columns = [['Coefficient', 'Intercept', 'Rsquared']])\n",
        "\n",
        "# Generate list of years that are missed\n",
        "predList = [1978,1979,1981,1982,1983,1984,1985,1986,1987,1988,\n",
        "            1989,1991,1992,1993,1994,1995,1996,1997,1998,1999, 2018]\n",
        "\n",
        "# Generate COLI prediction grid\n",
        "predCOLI = pd.DataFrame(columns = stateList, index = predList)\n",
        "\n",
        "# Convert predList and yearList to 2D array for sklearn\n",
        "predList2D = np.reshape(predList, (-1,1))\n",
        "yearList2D = np.reshape(yearList, (-1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3Wuws9djAdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create instance of class\n",
        "model = LinearRegression()\n",
        "\n",
        "# Regress deflator on year\n",
        "for i in stateList:\n",
        "  model.fit(yearList2D, COLI[i])\n",
        "  reg.loc[i, 'Coefficient'] = model.coef_.item(0)\n",
        "  reg.loc[i, 'Intercept'] = model.intercept_\n",
        "  reg.loc[i, 'Rsquared'] = model.score(yearList2D, COLI[i])\n",
        "  predCOLI[i] = model.predict(predList2D)\n",
        "\n",
        "# Concatinate available data and inferred data\n",
        "COLI = pd.concat([COLI, predCOLI])\n",
        "COLI = COLI.sort_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EgQUSzT-sMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute average COLI\n",
        "avgCOLI = COLI.mean(axis = 1)\n",
        "avgCOLI = pd.DataFrame(avgCOLI)\n",
        "avgCOLI = avgCOLI.rename(columns = {0: \"AVG_COLI\"})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otbd1xVvW737",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalize COLI by average COLI by year\n",
        "for y in range(1978, 2019): \n",
        "  COLI.loc[y] = COLI.loc[y]/avgCOLI.loc[y,'AVG_COLI']\n",
        "\n",
        "# Drop year 1970\n",
        "COLI.drop(index = 1970, inplace = True )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGadNMJHRBRe",
        "colab_type": "text"
      },
      "source": [
        "## 1.2. Consumer Price Index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W6BMMtk87E-",
        "colab_type": "code",
        "outputId": "97372e11-7cb9-4e8d-8b59-d671ef751c97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Import CPI\n",
        "CPI = pd.read_csv(in_path + \"CPI.csv\", index_col=\"YEAR\")\n",
        "CPI.drop_duplicates(keep='first', inplace=True)\n",
        "CPI.dropna(inplace=True)\n",
        "CPI.rename(columns = {'CPI99':'PriceIndex'}, inplace = True)\n",
        "\n",
        "# Convert price index to 2018 dollar from 1999 dollar\n",
        "CPI = CPI/CPI.loc[2018, 'PriceIndex']\n",
        "\n",
        "# Compute CPI by inverting price index of previous year\n",
        "CPI[\"CPI\"] = np.nan\n",
        "# (Not compute the very first CPI because the price index is not available)\n",
        "for i in CPI.index[1:len(CPI.index)]:\n",
        "  CPI.loc[i, 'CPI'] = 1/ CPI.loc[i-1, 'PriceIndex']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQsNFVNDROC_",
        "colab_type": "text"
      },
      "source": [
        "## 1.3. Deflator = COLI * CPI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX7EbWx69aEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate final deflator dataframes\n",
        "deflator = pd.DataFrame(data = COLI, index = range(1978, 2019), columns = stateList) \n",
        "\n",
        "# Transpose deflator\n",
        "deflator = deflator.T\n",
        "\n",
        "# Compute deflator from COLI and CPI\n",
        "for i in range(1978, 2019):\n",
        "  deflator[i] = deflator[i] * CPI.loc[i-1, 'CPI']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IecxxRdd5fY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Flatten deflator matrix\n",
        "flat = np.matrix(deflator).flatten()\n",
        "flat = pd.DataFrame(flat)\n",
        "flat = flat.T\n",
        "flat.rename(columns = {0: 'DEFLATOR'}, inplace = True)\n",
        "\n",
        "# Index YEAR\n",
        "year_Deflator = np.arange(1978, 2019, 1)\n",
        "year_Deflator_multiply = np.tile(year_Deflator,len(stateList))\n",
        "flat['YEAR'] = year_Deflator_multiply\n",
        "\n",
        "# Index STATEFIP\n",
        "stateDeflator_multiply = np.tile(stateList,len(year_Deflator))\n",
        "stateDeflator_multiply.sort()\n",
        "flat['STATEFIP'] = stateDeflator_multiply"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTF32ok9o0JN",
        "colab_type": "text"
      },
      "source": [
        "# Section 2. Data processor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wktCmel8mGfg",
        "colab_type": "text"
      },
      "source": [
        "## 2.1. Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwCWUgqO9LHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import raw data\n",
        "raw = pd.read_csv(in_path + \"raw.csv\")\n",
        "\n",
        "# Select data with HFLAG != 1 and then drop HFLAG\n",
        "raw = raw[raw.HFLAG != 1]\n",
        "raw = raw.drop(columns = ['HFLAG'])\n",
        "# Generate size\n",
        "raw[\"SIZE\"] = np.nan\n",
        "\n",
        "raw.loc[raw[\"PERNUM\"] == 1, \"SIZE\"] = 1\n",
        "raw.loc[(raw[\"PERNUM\"] != 1) & (raw[\"AGE\"] > 16), \"SIZE\"] = 0.7\n",
        "raw.loc[(raw[\"PERNUM\"] != 1) & (raw[\"AGE\"] <= 16), \"SIZE\"] = 0.5\n",
        "\n",
        "# Generate family ID\n",
        "raw[\"FAMID\"] = np.nan\n",
        "length = sum(raw.loc[raw['PERNUM'] == 1, 'PERNUM'])\n",
        "raw.loc[raw['PERNUM'] == 1, 'FAMID'] = np.arange(length)\n",
        "raw = raw.fillna(method='pad')\n",
        "\n",
        "# Generate effective size\n",
        "effsize = raw.groupby(['FAMID'])['SIZE'].agg('sum').reset_index()\n",
        "\n",
        "# Merge effective size with raw\n",
        "raw = pd.merge(raw, effsize, on = [\"FAMID\"])\n",
        "\n",
        "# Rename 'sizes'\n",
        "raw = raw.rename(columns={'SIZE_x': 'SIZE', 'SIZE_y': 'EFFSIZE'})\n",
        "\n",
        "# Eliminate observations that has PERNUM != 1\n",
        "raw = raw[raw.PERNUM == 1]\n",
        "raw = raw.drop(columns = ['PERNUM'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsvmHfef6BBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Merge raw anf flatten deflator on YEAR and STATEFIP\n",
        "raw = pd.merge(raw, flat, on = [\"YEAR\", \"STATEFIP\"])\n",
        "\n",
        "# Generate deflated household income column\n",
        "raw[\"DHHINCOME\"] = np.nan\n",
        "raw.DHHINCOME = raw.HHINCOME/(raw.DEFLATOR*raw.EFFSIZE)\n",
        "\n",
        "# Generate cumulative weight and percentage\n",
        "raw[\"CUMWT\"] = np.nan\n",
        "raw[\"PERCENT\"] = np.nan\n",
        "\n",
        "# Import formating components\n",
        "codeFirst_oneYear = pd.read_csv(in_path + \"codeFirst_oneYear.csv\", index_col = 0)\n",
        "codeThird_oneYear = pd.read_csv(in_path + \"codeThird_oneYear.csv\", index_col = 0)\n",
        "\n",
        "# Create constant\n",
        "stateList = [1,2,4,5,6,8,9,10,11,12,13,15,16,17,18,19,20,21,22,23,24,25,26,27,\n",
        "             28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,44,45,46,47,48,49,\n",
        "             50,51,53,54,55,56]\n",
        "\n",
        "d_ile = [0.05,0.15,0.25,0.35,0.45,0.50,0.55,0.65,0.75,0.85,0.95]\n",
        "\n",
        "p_ile = [0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1,0.11,0.12,0.13,0.14,0.15,\n",
        "          0.16,0.17,0.18,0.19,0.2,0.21,0.22,0.23,0.24,0.25,0.26,0.27,0.28,0.29,\n",
        "          0.3,0.31,0.32,0.33,0.34,0.35,0.36,0.37,0.38,0.39,0.4,0.41,0.42,0.43,\n",
        "          0.44,0.45,0.46,0.47,0.48,0.49,0.5,0.51,0.52,0.53,0.54,0.55,0.56,0.57,\n",
        "          0.58,0.59,0.6,0.61,0.62,0.63,0.64,0.65,0.66,0.67,0.68,0.69,0.7,0.71,\n",
        "          0.72,0.73,0.74,0.75,0.76,0.77,0.78,0.79,0.8,0.81,0.82,0.83,0.84,0.85,\n",
        "          0.86,0.87,0.88,0.89,0.9,0.91,0.92,0.93,0.94,0.95,0.96,0.97,0.98,0.99]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v_4mOoYvDP2",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 Generate k-ile graphs for each year"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xz0ROsK_wpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Choose k: decile ('d') or percentile ('p')\n",
        "k = 'd'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-l6PjgVB6zf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if (k == 'd'):\n",
        "  k_ile = d_ile\n",
        "\n",
        "  elif (k == 'p'):\n",
        "    k_ile = p_ile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEBTqSiqpemO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for y in range(1978, 2019):\n",
        "  # Generate year dataframe\n",
        "  year = raw[raw.YEAR == y]\n",
        "\n",
        "  # Generate result grid, decile-column\n",
        "  result = pd.DataFrame(data=None, index=np.arange(0,11,1), columns=stateList)\n",
        "\n",
        "  # Iterate through each state\n",
        "  c = 0\n",
        "  for i in stateList:\n",
        "    # Generate state dataframe\n",
        "    state = year[year.STATEFIP == i]\n",
        "    state = state.reset_index(drop = True)\n",
        "\n",
        "    # Sort state dataframe by DHHINCOME\n",
        "    state = state.sort_values('DHHINCOME')\n",
        "    \n",
        "    # Calculate cumulated weight and Percentage\n",
        "    state.CUMWT = state.ASECWTH.cumsum()\n",
        "    state.PERCENT = state.CUMWT/(state.ASECWTH.sum())\n",
        "    \n",
        "    # Calculate decile\n",
        "    r = 0\n",
        "    for d in decile:\n",
        "      result.iloc[r,c] = state.loc[state['PERCENT'] <= d, 'DHHINCOME'].max()\n",
        "      r = r + 1\n",
        "    c = c + 1\n",
        "\n",
        "  # Transpose result table: column-decile\n",
        "  result = result.transpose()\n",
        "\n",
        "  # Type casting result.index (type casting STATEFIP) to integer\n",
        "  result.index = result.index.map(int)\n",
        "\n",
        "  # Merge state dataframe with code dataframe\n",
        "  result = pd.merge(codeFirst_oneYear, result, left_index = True, right_index = True)\n",
        "  result = pd.merge(result, codeThird_oneYear, left_index = True, right_index = True)\n",
        "\n",
        "  # Compute state population and normalized state population\n",
        "  result[\"POP\"] = np.nan\n",
        "  result.POP = year.groupby(['STATEFIP'])['ASECWT'].agg('sum')\n",
        "\n",
        "  result[\"NORMPOP\"] = np.nan\n",
        "  result.NORMPOP = round(result.POP/(result.POP.min()))\n",
        "\n",
        "  # Replicate each state's dataline with its respected replication number\n",
        "  for i in stateList:\n",
        "    rep = result.loc[i,'NORMPOP'] - 1\n",
        "    rep = int(rep)\n",
        "    line = result[result.index == i].copy()\n",
        "    line.name = i\n",
        "    line.loc[i, 'Label'] = ''\n",
        "    for i in range(0,rep): result = result.append(line)\n",
        "\n",
        "  # Drop population and normalized population\n",
        "  result = result.drop(columns = ['POP', 'NORMPOP'])\n",
        "\n",
        "  # Sort the result by median\n",
        "  result = result.sort_values(by = [5], ascending = True)\n",
        "\n",
        "  # Rename index column and role\n",
        "  result = result.rename(index = str, columns = {0: \"5p\", 1: \"15p\", 2: \"25p\", 3: \"35p\", 4: \"45p\", 5: \"50p\",\n",
        "                                                6: \"55p\", 7: \"65p\", 8: \"75p\", 9: \"85p\", 10: \"95p\"})\n",
        "\n",
        "  # Export result grid  \n",
        "  result.to_csv(out_path + 'year_d/' + str(y) + '_d.csv')\n",
        "\n",
        "  # Convert dataframe to JSON\n",
        "  result = result.to_json(orient = 'records')\n",
        "  result = json.loads(result, object_pairs_hook = OrderedDict)\n",
        "\n",
        "  # Make JSON format readable\n",
        "  result = json.dumps(result, indent = 4, sort_keys = False)\n",
        "\n",
        "  # Save JSON to text format\n",
        "  with open(out_path + 'year_d/' + str(y) + '_d.txt', 'w') as f:\n",
        "    f.writelines(result)\n",
        "\n",
        "  # Glue data with html environment\n",
        "  filenames = [in_path + 'first_d_oneYear.txt', out_path + 'year_d/' + str(y) + '_d.txt',\n",
        "              in_path + 'third.txt']\n",
        "  with open(out_path + 'year_d/' + str(y) + '_d.html', 'w') as outfile:\n",
        "    for i in filenames:\n",
        "      with open (i) as infile:\n",
        "        outfile.write(infile.read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkdlzjbrwJQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJQIyvrrwX0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STOP here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLZUPqLumKgz",
        "colab_type": "text"
      },
      "source": [
        "## year_p\n",
        "\n",
        "There are 4 differences between d_files and p_files:\n",
        "\n",
        "*   Deciles\n",
        "*   Loop to construct result grid sheet (0 to 98 instead of 0 to 11)\n",
        "*   Use first_p instead of first_d (look at pCodeGenerator excel file for detail about p_code generator)\n",
        "*   out_path: use year_p_gsp_data instead of year_d_gsp_data\n",
        "*   Change name when export data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrjWsL9mmaD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from collections import OrderedDict\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "in_path = 'gdrive/My Drive/Colab Notebooks/code/'\n",
        "out_path = 'gdrive/My Drive/Colab Notebooks/oneYear/year_p/'\n",
        "\n",
        "# Import raw data state codes, color codes, and deflator\n",
        "raw = pd.read_csv(in_path + \"raw.csv\")\n",
        "codeFirst_oneYear = pd.read_csv(in_path + \"codeFirst_oneYear.csv\", index_col = 0)\n",
        "codeThird_oneYear = pd.read_csv(in_path + \"codeThird_oneYear.csv\", index_col = 0)\n",
        "deflator = pd.read_csv(in_path + \"COLI.csv\")\n",
        "\n",
        "# Generate constants\n",
        "stateList = [1,2,4,5,6,8,9,10,11,12,13,15,16,17,18,19,20,21,22,23,24,25,26,27,\n",
        "             28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,44,45,46,47,48,49,\n",
        "             50,51,53,54,55,56]\n",
        "decile = [0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1,0.11,0.12,0.13,0.14,0.15,\n",
        "          0.16,0.17,0.18,0.19,0.2,0.21,0.22,0.23,0.24,0.25,0.26,0.27,0.28,0.29,\n",
        "          0.3,0.31,0.32,0.33,0.34,0.35,0.36,0.37,0.38,0.39,0.4,0.41,0.42,0.43,\n",
        "          0.44,0.45,0.46,0.47,0.48,0.49,0.5,0.51,0.52,0.53,0.54,0.55,0.56,0.57,\n",
        "          0.58,0.59,0.6,0.61,0.62,0.63,0.64,0.65,0.66,0.67,0.68,0.69,0.7,0.71,\n",
        "          0.72,0.73,0.74,0.75,0.76,0.77,0.78,0.79,0.8,0.81,0.82,0.83,0.84,0.85,\n",
        "          0.86,0.87,0.88,0.89,0.9,0.91,0.92,0.93,0.94,0.95,0.96,0.97,0.98,0.99]\n",
        "value = ['','','','','','','','','','','','','','','','','','','','','','',\n",
        "         '','','','','','','','','','','','','','','','','','','','','','',\n",
        "         '','','','','','','']\n",
        "\n",
        "# Iterate through each year\n",
        "for y in range(1978, 1979):\n",
        "  \n",
        "  # Generate result grid, decile-column\n",
        "  result = pd.DataFrame(columns = stateList)\n",
        "  for i in range(0, 98): result.loc[i] = value\n",
        "  \n",
        "  # Generate year dataframe\n",
        "  year = raw[raw.YEAR == y]\n",
        "  \n",
        "  # Eliminate observations that has PERNUM != 1\n",
        "  person = year[year.PERNUM == 1]\n",
        "  \n",
        "  # Merge 2 file: for raw, every row that has STATEFIP and YEAR match with \n",
        "  # that row in deflator will get the same deflator value.\n",
        "  person = pd.merge(person, deflator, on = [\"YEAR\",\"STATEFIP\"])\n",
        "  \n",
        "  # Rearrange culumns order\n",
        "  person = person[['YEAR', 'ASECWTH', 'STATEFIP', 'HHINCOME', 'PERNUM', \n",
        "                   'ASECWT','DEFLATOR','SEX','RACE','HISPAN','EDUC']]\n",
        "  \n",
        "  # Generate deflated household income column\n",
        "  person.insert(7, 'DHHINCOME', '')\n",
        "  \n",
        "  # Iterate through the entire 'person' to calculate deflated income\n",
        "  for i in range (0, len(person)):\n",
        "    person.iloc[i, 7] = person.iloc[i, 3]/person.iloc[i, 6]\n",
        "  \n",
        "  # Sort the remainded observation by STATEFIP\n",
        "  person.sort_values('STATEFIP')\n",
        "  \n",
        "  # Iterate through each state\n",
        "  c = 0\n",
        "  for i in stateList:\n",
        "    # Generate state dataframe\n",
        "    state = person[person.STATEFIP == i]\n",
        "    \n",
        "    # Sort state dataframe by HHINCOME\n",
        "    state = state.sort_values('HHINCOME')\n",
        "    \n",
        "    # Calculate cumulated weight and Percentage\n",
        "    state.insert(8, 'CUMWT', '')\n",
        "    state.insert(9, 'PERCENT', '')\n",
        "    state.iloc[0, 8] = state.iloc[0, 1]\n",
        "    state.iloc[0, 9] = state.iloc[0, 8]/(state.sum().ASECWT)\n",
        "    for i in range (1, len(state)):\n",
        "      state.iloc[i, 8] = state.iloc[i-1, 8] + state.iloc[i, 1]\n",
        "      state.iloc[i, 9] = state.iloc[i, 8]/(state.sum().ASECWT)\n",
        "    \n",
        "    # Calculate decile\n",
        "    r = 0\n",
        "    for d in decile:\n",
        "      for i in range (0, len(state)):\n",
        "        if (d < state.iloc[i, 9]):\n",
        "          result.iloc[r,c] = state.iloc[i, 7]\n",
        "          r = r + 1\n",
        "          break\n",
        "    c = c + 1\n",
        "    \n",
        "  # Transpose result table: column-decile\n",
        "  result = result.transpose()\n",
        "\n",
        "  # Type casting result.index (type casting STATEFIP) to integer\n",
        "  result.index = result.index.map(int)\n",
        "\n",
        "  # Merge state dataframe with code dataframe\n",
        "  result = pd.merge(codeFirst_oneYear, result, left_index = True, right_index = True)\n",
        "  result = pd.merge(result, codeThird_oneYear, left_index = True, right_index = True)\n",
        "\n",
        "  result.insert(101, 'POP','')\n",
        "  r = 0\n",
        "  for i in stateList:\n",
        "    state = year[year.STATEFIP == i]\n",
        "    result.iloc[r, 101] = state.sum().ASECWT\n",
        "    r = r + 1\n",
        "\n",
        "  result.insert(102, 'NORMPOP', '')\n",
        "  for i in range(0, len(result)):\n",
        "    result.iloc[i, 102] = round(result.iloc[i, 101]/(result['POP'].min()))\n",
        "\n",
        "  for i in stateList:\n",
        "    rep = result.loc[int(i),'NORMPOP'] - 1\n",
        "    rep = int(rep)\n",
        "    # The following statement need .copy() at the end for explicit reason\n",
        "    # More information: https://www.dataquest.io/blog/settingwithcopywarning/\n",
        "    line = result[result.index == i].copy()\n",
        "    line.name = i\n",
        "    line.iloc[0, 99] = ''\n",
        "    for i in range(0,rep): result = result.append(line)\n",
        "        \n",
        "  # result.to_csv(out_path+str(y)+'withPop.csv')\n",
        "  result = result.drop(columns = ['POP', 'NORMPOP'])\n",
        "      \n",
        "  # Sort the result by median\n",
        "  result = result.sort_values(48, ascending = True)\n",
        "\n",
        "  # Rename index column and role\n",
        "  result = result.rename(index = str, columns = {0: \"2p\", 1: \"3p\", 2: \"4p\", 3: \"5p\",\n",
        "                                                 4: \"6p\", 5: \"7p\", 6: \"8p\", 7: \"9p\",\n",
        "                                                 8: \"10p\", 9: \"11p\", 10: \"12p\",\n",
        "                                                 11: \"13p\", 12: \"14p\", 13: \"15p\",\n",
        "                                                 14: \"16p\", 15: \"17p\", 16: \"18p\",\n",
        "                                                 17: \"19p\", 18: \"20p\", 19: \"21p\",\n",
        "                                                 20: \"22p\", 21: \"23p\", 22: \"24p\",\n",
        "                                                 23: \"25p\", 24: \"26p\", 25: \"27p\",\n",
        "                                                 26: \"28p\", 27: \"29p\", 28: \"30p\",\n",
        "                                                 29: \"31p\", 30: \"32p\", 31: \"33p\",\n",
        "                                                 32: \"34p\", 33: \"35p\", 34: \"36p\",\n",
        "                                                 35: \"37p\", 36: \"38p\", 37: \"39p\",\n",
        "                                                 38: \"40p\", 39: \"41p\", 40: \"42p\",\n",
        "                                                 41: \"43p\", 42: \"44p\", 43: \"45p\",\n",
        "                                                 44: \"46p\", 45: \"47p\", 46: \"48p\",\n",
        "                                                 47: \"49p\", 48: \"50p\", 49: \"51p\",\n",
        "                                                 50: \"52p\", 51: \"53p\", 52: \"54p\",\n",
        "                                                 53: \"55p\", 54: \"56p\", 55: \"57p\",\n",
        "                                                 56: \"58p\", 57: \"59p\", 58: \"60p\",\n",
        "                                                 59: \"61p\", 60: \"62p\", 61: \"63p\",\n",
        "                                                 62: \"64p\", 63: \"65p\", 64: \"66p\",\n",
        "                                                 65: \"67p\", 66: \"68p\", 67: \"69p\",\n",
        "                                                 68: \"70p\", 69: \"71p\", 70: \"72p\",\n",
        "                                                 71: \"73p\", 72: \"74p\", 73: \"75p\",\n",
        "                                                 74: \"76p\", 75: \"77p\", 76: \"78p\",\n",
        "                                                 77: \"79p\", 78: \"80p\", 79: \"81p\",\n",
        "                                                 80: \"82p\", 81: \"83p\", 82: \"84p\",\n",
        "                                                 83: \"85p\", 84: \"86p\", 85: \"87p\",\n",
        "                                                 86: \"88p\", 87: \"89p\", 88: \"90p\",\n",
        "                                                 89: \"91p\", 90: \"92p\", 91: \"93p\",\n",
        "                                                 92: \"94p\", 93: \"95p\", 94: \"96p\",\n",
        "                                                 95: \"97p\", 96: \"98p\", 97: \"99p\"})\n",
        "  \n",
        "  result.to_csv(out_path+str(y) + '_p.csv')\n",
        "\n",
        "  # Convert dataframe to JSON\n",
        "  result = result.to_json(orient = 'records')\n",
        "  result = json.loads(result, object_pairs_hook = OrderedDict)\n",
        "\n",
        "  # Make JSON format readable\n",
        "  result = json.dumps(result, indent = 4, sort_keys = False)\n",
        "\n",
        "  # Save JSON to text format\n",
        "  with open(out_path + str(y) + '_p.txt', 'w') as f:\n",
        "    f.writelines(result)\n",
        "\n",
        "  # Glue data with html environment\n",
        "  filenames = [in_path + 'first_p_oneYear.txt', out_path + str(y) + '_p.txt',\n",
        "               in_path + 'third.txt']\n",
        "  with open(out_path + str(y) + '_p.html', 'w') as outfile:\n",
        "    for i in filenames:\n",
        "      with open (i) as infile:\n",
        "        outfile.write(infile.read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-SjerHFco5M",
        "colab_type": "text"
      },
      "source": [
        "## state_d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAWX38PvNgt4",
        "colab_type": "code",
        "outputId": "c4b23688-a898-4718-8c58-69eff0503760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from collections import OrderedDict\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "in_path = 'gdrive/My Drive/Colab Notebooks/code/'\n",
        "out_path = 'gdrive/My Drive/Colab Notebooks/oneState/state_d/'\n",
        "\n",
        "# Import raw data state codes, color codes, and deflator\n",
        "raw = pd.read_csv(in_path + \"raw.csv\")\n",
        "codeFirst_oneState = pd.read_csv(in_path + \"codeFirst_oneState.csv\", index_col = 0)\n",
        "codeThird_oneState = pd.read_csv(in_path + \"codeThird_oneState.csv\", index_col = 0)\n",
        "deflator = pd.read_csv(in_path +\"COLI.csv\")\n",
        "\n",
        "# Select data with HFLAG != 1 and then drop HFLAG\n",
        "raw = raw[raw.HFLAG != 1]\n",
        "raw = raw.drop(columns = ['HFLAG'])\n",
        "\n",
        "# Generate constants\n",
        "stateList = [1,2,4,5,6,8,9,10,11,12,13,15,16,17,18,19,20,21,22,23,24,25,26,27,\n",
        "             28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,44,45,46,47,48,49,\n",
        "             50,51,53,54,55,56]\n",
        "\n",
        "# stateList = [12]\n",
        "\n",
        "decile = [0.05,0.15,0.25,0.35,0.45,0.50,0.55,0.65,0.75,0.85,0.95]\n",
        "value = ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
        "         '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
        "         '', '', '', '', '']\n",
        "yearList = [1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988,\n",
        "            1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999,\n",
        "            2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010,\n",
        "            2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018]\n",
        "\n",
        "# Iterate through each state\n",
        "for s in stateList:\n",
        "  \n",
        "  # Generate result grid, decile-column\n",
        "  result = pd.DataFrame(columns = yearList)\n",
        "  for i in range(0, 11): result.loc[i] = value\n",
        "  \n",
        "  # Generate state dataframe\n",
        "  state = raw[raw.STATEFIP == s]\n",
        "\n",
        "  # Eliminate observations that has PERNUM != 1\n",
        "  person = state[state.PERNUM == 1]\n",
        "  \n",
        "  # Merge 2 file: for raw, every row that has STATEFIP and YEAR match with \n",
        "  # that row in deflator will get the same deflator value.\n",
        "  person = pd.merge(person, deflator, on = [\"YEAR\",\"STATEFIP\"])\n",
        "  \n",
        "  # Rearrange culumns order\n",
        "  person = person[['YEAR', 'ASECWTH', 'STATEFIP', 'HHINCOME', 'PERNUM', \n",
        "                   'ASECWT','DEFLATOR','SEX','RACE','HISPAN','EDUC']]\n",
        "  \n",
        "  # Generate deflated household income column\n",
        "  person.insert(7, 'DHHINCOME', '')\n",
        "  \n",
        "  # Iterate through the entire 'person' to calculate deflated income\n",
        "  for i in range (0, len(person)):\n",
        "    person.iloc[i, 7] = person.iloc[i, 3]/person.iloc[i, 6]\n",
        "  \n",
        "  # Sort the remainded observation by YEAR\n",
        "  person.sort_values('YEAR')\n",
        "  \n",
        "  # Iterate through each year\n",
        "  c = 0\n",
        "  for i in yearList:\n",
        "    # Generate year dataframe\n",
        "    year = person[person.YEAR == i]\n",
        "    \n",
        "    # Sort year dataframe by HHINCOME\n",
        "    year = year.sort_values('HHINCOME')\n",
        "    \n",
        "    # Calculate cumulated weight and Percentage\n",
        "    year.insert(8, 'CUMWT', '')\n",
        "    year.insert(9, 'PERCENT', '')\n",
        "    year.iloc[0, 8] = year.iloc[0, 1]\n",
        "    year.iloc[0, 9] = year.iloc[0, 8]/(year.sum().ASECWT)\n",
        "    for i in range (1, len(year)):\n",
        "      year.iloc[i, 8] = year.iloc[i-1, 8] + year.iloc[i, 1]\n",
        "      year.iloc[i, 9] = year.iloc[i, 8]/(year.sum().ASECWT)\n",
        "    \n",
        "    # Calculate decile\n",
        "    r = 0\n",
        "    for d in decile:\n",
        "      for i in range (0, len(year)):\n",
        "        if (d < year.iloc[i, 9]):\n",
        "          result.iloc[r,c] = year.iloc[i, 7]\n",
        "          r = r + 1\n",
        "          break\n",
        "    c = c + 1\n",
        "    \n",
        "  # Transpose result table: column-decile\n",
        "  result = result.transpose()\n",
        "\n",
        "  # Type casting result.index (type casting YEAR) to integer\n",
        "  result.index = result.index.map(int)\n",
        "\n",
        "  # Merge state dataframe with code dataframe\n",
        "  result = pd.merge(codeFirst_oneState, result, left_index = True, right_index = True)\n",
        "  result = pd.merge(result, codeThird_oneState, left_index = True, right_index = True)\n",
        "\n",
        "  result.insert(14, 'POP','')\n",
        "  r = 0\n",
        "  for i in yearList:\n",
        "    year = state[state.YEAR == i]\n",
        "    result.iloc[r, 14] = year.sum().ASECWT\n",
        "    r = r + 1\n",
        "\n",
        "  result.insert(15, 'NORMPOP', '')\n",
        "  for i in range(0, len(result)):\n",
        "    result.iloc[i, 15] = round(10*(result.iloc[i, 14])/(result['POP'].min()))\n",
        "#     result.iloc[i, 15] = result.iloc[i, 14]/(result['POP'].min())\n",
        "  for i in yearList:\n",
        "    rep = result.loc[int(i),'NORMPOP'] - 1\n",
        "    rep = int(rep)\n",
        "    # The following statement need .copy() at the end for explicit reason\n",
        "    # More information: https://www.dataquest.io/blog/settingwithcopywarning/\n",
        "    line = result[result.index == i].copy()\n",
        "    line.name = i\n",
        "    # Remove the name of the state (so that the name does not repeat too many time)\n",
        "    line.iloc[0, 12] = ''\n",
        "    for i in range(0,rep): result = result.append(line)\n",
        "        \n",
        "#   # result.to_csv(out_path+str(y)+'withPop.csv')\n",
        "  result = result.drop(columns = ['POP', 'NORMPOP'])\n",
        "      \n",
        "  # Sort the result by year\n",
        "  result = result.sort_values(\"Year\", ascending = True)\n",
        "\n",
        "  # Rename index column and role\n",
        "  result = result.rename(index = str, columns = {0: \"5p\", 1: \"15p\", 2: \"25p\",\n",
        "                                                 3: \"35p\", 4: \"45p\", 5: \"50p\",\n",
        "                                                 6: \"55p\", 7: \"65p\", 8: \"75p\",\n",
        "                                                 9: \"85p\", 10: \"95p\"})\n",
        "  \n",
        "  result.to_csv(out_path+str(s) + '_d.csv')\n",
        "\n",
        "  # Convert dataframe to JSON\n",
        "  result = result.to_json(orient = 'records')\n",
        "  result = json.loads(result, object_pairs_hook = OrderedDict)\n",
        "\n",
        "  # Make JSON format readable\n",
        "  result = json.dumps(result, indent = 4, sort_keys = False)\n",
        "\n",
        "  # Save JSON to text format\n",
        "  with open(out_path + str(s) + '_d.txt', 'w') as f:\n",
        "    f.writelines(result)\n",
        "\n",
        "  # Glue data with html environment\n",
        "  filenames = [in_path + 'first_d_oneState.txt', out_path + str(s) + '_d.txt',\n",
        "               in_path + 'third.txt']\n",
        "  with open(out_path + str(s) + '_d.html', 'w') as outfile:\n",
        "    for i in filenames:\n",
        "      with open (i) as infile:\n",
        "        outfile.write(infile.read())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skDocBwlc6js",
        "colab_type": "text"
      },
      "source": [
        "## state_p"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxIlCwJ5c53b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from collections import OrderedDict\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "in_path = 'gdrive/My Drive/Colab Notebooks/code/'\n",
        "out_path = 'gdrive/My Drive/Colab Notebooks/oneState/state_p/'\n",
        "\n",
        "# Import raw data state codes, color codes, and deflator\n",
        "raw = pd.read_csv(in_path + \"raw.csv\")\n",
        "codeFirst_oneState = pd.read_csv(in_path + \"codeFirst_oneState.csv\", index_col = 0)\n",
        "codeThird_oneState = pd.read_csv(in_path + \"codeThird_oneState.csv\", index_col = 0)\n",
        "deflator = pd.read_csv(in_path + \"COLI.csv\")\n",
        "\n",
        "# Generate constants\n",
        "stateList = [1,2,4,5,6,8,9,10,11,12,13,15,16,17,18,19,20,21,22,23,24,25,26,27,\n",
        "             28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,44,45,46,47,48,49,\n",
        "             50,51,53,54,55,56]\n",
        "\n",
        "# stateList = [11]\n",
        "\n",
        "decile = [0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1,0.11,0.12,0.13,0.14,0.15,\n",
        "          0.16,0.17,0.18,0.19,0.2,0.21,0.22,0.23,0.24,0.25,0.26,0.27,0.28,0.29,\n",
        "          0.3,0.31,0.32,0.33,0.34,0.35,0.36,0.37,0.38,0.39,0.4,0.41,0.42,0.43,\n",
        "          0.44,0.45,0.46,0.47,0.48,0.49,0.5,0.51,0.52,0.53,0.54,0.55,0.56,0.57,\n",
        "          0.58,0.59,0.6,0.61,0.62,0.63,0.64,0.65,0.66,0.67,0.68,0.69,0.7,0.71,\n",
        "          0.72,0.73,0.74,0.75,0.76,0.77,0.78,0.79,0.8,0.81,0.82,0.83,0.84,0.85,\n",
        "          0.86,0.87,0.88,0.89,0.9,0.91,0.92,0.93,0.94,0.95,0.96,0.97,0.98,0.99]\n",
        "\n",
        "value = ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
        "         '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
        "         '', '', '', '', '']\n",
        "\n",
        "yearList = [1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988,\n",
        "            1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999,\n",
        "            2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010,\n",
        "            2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018]\n",
        "\n",
        "# Iterate through each state\n",
        "for s in stateList:\n",
        "  \n",
        "  # Generate result grid, decile-column\n",
        "  result = pd.DataFrame(columns = yearList)\n",
        "  for i in range(0, 98): result.loc[i] = value\n",
        "  \n",
        "  # Generate state dataframe\n",
        "  state = raw[raw.STATEFIP == s]\n",
        "\n",
        "  # Eliminate observations that has PERNUM != 1\n",
        "  person = state[state.PERNUM == 1]\n",
        "  \n",
        "  # Merge 2 file: for raw, every row that has STATEFIP and YEAR match with \n",
        "  # that row in deflator will get the same deflator value.\n",
        "  person = pd.merge(person, deflator, on = [\"YEAR\",\"STATEFIP\"])\n",
        "  \n",
        "  # Rearrange culumns order\n",
        "  person = person[['YEAR', 'ASECWTH', 'STATEFIP', 'HHINCOME', 'PERNUM', \n",
        "                   'ASECWT','DEFLATOR','SEX','RACE','HISPAN','EDUC']]\n",
        "  \n",
        "  # Generate deflated household income column\n",
        "  person.insert(7, 'DHHINCOME', '')\n",
        "  \n",
        "  # Iterate through the entire 'person' to calculate deflated income\n",
        "  for i in range (0, len(person)):\n",
        "    person.iloc[i, 7] = person.iloc[i, 3]/person.iloc[i, 6]\n",
        "  \n",
        "  # Sort the remainded observation by YEAR\n",
        "  person.sort_values('YEAR')\n",
        "  \n",
        "  # Iterate through each year\n",
        "  c = 0\n",
        "  for i in yearList:\n",
        "    # Generate year dataframe\n",
        "    year = person[person.YEAR == i]\n",
        "    \n",
        "    # Sort year dataframe by HHINCOME\n",
        "    year = year.sort_values('HHINCOME')\n",
        "    \n",
        "    # Calculate cumulated weight and Percentage\n",
        "    year.insert(8, 'CUMWT', '')\n",
        "    year.insert(9, 'PERCENT', '')\n",
        "    year.iloc[0, 8] = year.iloc[0, 1]\n",
        "    year.iloc[0, 9] = year.iloc[0, 8]/(year.sum().ASECWT)\n",
        "    for i in range (1, len(year)):\n",
        "      year.iloc[i, 8] = year.iloc[i-1, 8] + year.iloc[i, 1]\n",
        "      year.iloc[i, 9] = year.iloc[i, 8]/(year.sum().ASECWT)\n",
        "    \n",
        "    # Calculate decile\n",
        "    r = 0\n",
        "    for d in decile:\n",
        "      for i in range (0, len(year)):\n",
        "        if (d < year.iloc[i, 9]):\n",
        "          result.iloc[r,c] = year.iloc[i, 7]\n",
        "          r = r + 1\n",
        "          break\n",
        "    c = c + 1\n",
        "    \n",
        "  # Transpose result table: column-decile\n",
        "  result = result.transpose()\n",
        "\n",
        "  # Type casting result.index (type casting YEAR) to integer\n",
        "  result.index = result.index.map(int)\n",
        "\n",
        "  # Merge state dataframe with code dataframe\n",
        "  result = pd.merge(codeFirst_oneState, result, left_index = True, right_index = True)\n",
        "  result = pd.merge(result, codeThird_oneState, left_index = True, right_index = True)\n",
        "\n",
        "  result.insert(14, 'POP','')\n",
        "  r = 0\n",
        "  for i in yearList:\n",
        "    year = state[state.YEAR == i]\n",
        "    result.iloc[r, 14] = year.sum().ASECWT\n",
        "    r = r + 1\n",
        "\n",
        "  result.insert(15, 'NORMPOP', '')\n",
        "  for i in range(0, len(result)):\n",
        "    result.iloc[i, 15] = round(result.iloc[i, 14]/(result['POP'].min()))\n",
        "\n",
        "  for i in yearList:\n",
        "    rep = result.loc[int(i),'NORMPOP'] - 1\n",
        "    rep = int(rep)\n",
        "    # The following statement need .copy() at the end for explicit reason\n",
        "    # More information: https://www.dataquest.io/blog/settingwithcopywarning/\n",
        "    line = result[result.index == i].copy()\n",
        "    line.name = i\n",
        "    # Remove the name of the state (so that the name does not repeat too many time)\n",
        "    line.iloc[0, 12] = ''\n",
        "    for i in range(0,rep): result = result.append(line)\n",
        "        \n",
        "#   # result.to_csv(out_path+str(y)+'withPop.csv')\n",
        "  result = result.drop(columns = ['POP', 'NORMPOP'])\n",
        "      \n",
        "  # Sort the result by year\n",
        "  result = result.sort_values(\"Year\", ascending = True)\n",
        "\n",
        "  # Rename index column and role\n",
        "  result = result.rename(index = str, columns = {0: \"2p\", 1: \"3p\", 2: \"4p\", 3: \"5p\",\n",
        "                                                 4: \"6p\", 5: \"7p\", 6: \"8p\", 7: \"9p\",\n",
        "                                                 8: \"10p\", 9: \"11p\", 10: \"12p\",\n",
        "                                                 11: \"13p\", 12: \"14p\", 13: \"15p\",\n",
        "                                                 14: \"16p\", 15: \"17p\", 16: \"18p\",\n",
        "                                                 17: \"19p\", 18: \"20p\", 19: \"21p\",\n",
        "                                                 20: \"22p\", 21: \"23p\", 22: \"24p\",\n",
        "                                                 23: \"25p\", 24: \"26p\", 25: \"27p\",\n",
        "                                                 26: \"28p\", 27: \"29p\", 28: \"30p\",\n",
        "                                                 29: \"31p\", 30: \"32p\", 31: \"33p\",\n",
        "                                                 32: \"34p\", 33: \"35p\", 34: \"36p\",\n",
        "                                                 35: \"37p\", 36: \"38p\", 37: \"39p\",\n",
        "                                                 38: \"40p\", 39: \"41p\", 40: \"42p\",\n",
        "                                                 41: \"43p\", 42: \"44p\", 43: \"45p\",\n",
        "                                                 44: \"46p\", 45: \"47p\", 46: \"48p\",\n",
        "                                                 47: \"49p\", 48: \"50p\", 49: \"51p\",\n",
        "                                                 50: \"52p\", 51: \"53p\", 52: \"54p\",\n",
        "                                                 53: \"55p\", 54: \"56p\", 55: \"57p\",\n",
        "                                                 56: \"58p\", 57: \"59p\", 58: \"60p\",\n",
        "                                                 59: \"61p\", 60: \"62p\", 61: \"63p\",\n",
        "                                                 62: \"64p\", 63: \"65p\", 64: \"66p\",\n",
        "                                                 65: \"67p\", 66: \"68p\", 67: \"69p\",\n",
        "                                                 68: \"70p\", 69: \"71p\", 70: \"72p\",\n",
        "                                                 71: \"73p\", 72: \"74p\", 73: \"75p\",\n",
        "                                                 74: \"76p\", 75: \"77p\", 76: \"78p\",\n",
        "                                                 77: \"79p\", 78: \"80p\", 79: \"81p\",\n",
        "                                                 80: \"82p\", 81: \"83p\", 82: \"84p\",\n",
        "                                                 83: \"85p\", 84: \"86p\", 85: \"87p\",\n",
        "                                                 86: \"88p\", 87: \"89p\", 88: \"90p\",\n",
        "                                                 89: \"91p\", 90: \"92p\", 91: \"93p\",\n",
        "                                                 92: \"94p\", 93: \"95p\", 94: \"96p\",\n",
        "                                                 95: \"97p\", 96: \"98p\", 97: \"99p\"})\n",
        "  \n",
        "  result.to_csv(out_path+str(s) + '_p.csv')\n",
        "\n",
        "  # Convert dataframe to JSON\n",
        "  result = result.to_json(orient = 'records')\n",
        "  result = json.loads(result, object_pairs_hook = OrderedDict)\n",
        "\n",
        "  # Make JSON format readable\n",
        "  result = json.dumps(result, indent = 4, sort_keys = False)\n",
        "\n",
        "  # Save JSON to text format\n",
        "  with open(out_path + str(s) + '_p.txt', 'w') as f:\n",
        "    f.writelines(result)\n",
        "\n",
        "  # Glue data with html environment\n",
        "  filenames = [in_path + 'first_p_oneState.txt', out_path + str(s) + '_p.txt',\n",
        "               in_path + 'third.txt']\n",
        "  with open(out_path + str(s) + '_p.html', 'w') as outfile:\n",
        "    for i in filenames:\n",
        "      with open (i) as infile:\n",
        "        outfile.write(infile.read())\n",
        "        \n",
        "        #Adjust max income \n",
        "        #Adjust household size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut0cz6WnTqoz",
        "colab_type": "text"
      },
      "source": [
        "References:\n",
        "\n",
        "*   Color generator: https://www.strangeplanet.fr/work/gradient-generator/index.php\n",
        "\n",
        "*   AmChart documentation:  https://docs.amcharts.com/3/javascriptcharts/AmGraph\n",
        "\n",
        "*   Jackblun's graph: https://jackblun.github.io/Globalinc/html/fig_1980.html"
      ]
    }
  ]
}